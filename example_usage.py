#!/usr/bin/env python3
"""
åˆ†é˜¶æ®µè®­ç»ƒç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹

æœ¬è„šæœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨åˆ†é˜¶æ®µè®­ç»ƒç³»ç»Ÿè¿›è¡ŒVLMçš„å…¨é‡å¾®è°ƒ
"""

import os
import sys
import subprocess
from pathlib import Path


def run_training_example():
    """
    è¿è¡Œè®­ç»ƒç¤ºä¾‹
    """
    print("=" * 60)
    print("åˆ†é˜¶æ®µè®­ç»ƒç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    # æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    required_files = [
        "train_staged.py",
        "staged_training.yaml", 
        "quick_start.yaml",
        "utils.py"
    ]
    
    missing_files = []
    for file in required_files:
        if not Path(file).exists():
            missing_files.append(file)
    
    if missing_files:
        print(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {missing_files}")
        print("è¯·ç¡®ä¿æ‰€æœ‰å¿…è¦æ–‡ä»¶éƒ½åœ¨å½“å‰ç›®å½•ä¸­")
        return False
    
    print("âœ… æ‰€æœ‰å¿…è¦æ–‡ä»¶æ£€æŸ¥é€šè¿‡")
    
    # ç¤ºä¾‹1: å¿«é€ŸéªŒè¯
    print("\n" + "="*40)
    print("ç¤ºä¾‹1: å¿«é€ŸéªŒè¯ï¼ˆé˜¶æ®µ1è®­ç»ƒï¼‰")
    print("="*40)
    
    print("è¿è¡Œå¿«é€ŸéªŒè¯è®­ç»ƒ...")
    try:
        result = subprocess.run([
            "python", "train_staged.py", "quick_start.yaml"
        ], capture_output=True, text=True, timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
        
        if result.returncode == 0:
            print("âœ… å¿«é€ŸéªŒè¯è®­ç»ƒæˆåŠŸå®Œæˆ")
        else:
            print(f"âŒ å¿«é€ŸéªŒè¯è®­ç»ƒå¤±è´¥: {result.stderr}")
            
    except subprocess.TimeoutExpired:
        print("â° å¿«é€ŸéªŒè¯è®­ç»ƒè¶…æ—¶ï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºè®­ç»ƒéœ€è¦æ—¶é—´ï¼‰")
    except Exception as e:
        print(f"âŒ è¿è¡Œå¿«é€ŸéªŒè¯æ—¶å‡ºé”™: {e}")
    
    # ç¤ºä¾‹2: å®Œæ•´è®­ç»ƒæµç¨‹
    print("\n" + "="*40)
    print("ç¤ºä¾‹2: å®Œæ•´è®­ç»ƒæµç¨‹ï¼ˆæ‰€æœ‰é˜¶æ®µï¼‰")
    print("="*40)
    
    print("æ³¨æ„: å®Œæ•´è®­ç»ƒæµç¨‹éœ€è¦è¾ƒé•¿æ—¶é—´å’Œæ›´å¤šè®¡ç®—èµ„æº")
    print("å»ºè®®åœ¨GPUç¯å¢ƒä¸‹è¿è¡Œ")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰GPU
    try:
        import torch
        if torch.cuda.is_available():
            print(f"âœ… æ£€æµ‹åˆ°GPU: {torch.cuda.get_device_name(0)}")
            print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
        else:
            print("âš ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œè®­ç»ƒå°†ä½¿ç”¨CPUï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
    except ImportError:
        print("âš ï¸  æ— æ³•æ£€æµ‹GPUçŠ¶æ€")
    
    print("\nè¦è¿è¡Œå®Œæ•´è®­ç»ƒæµç¨‹ï¼Œè¯·æ‰§è¡Œ:")
    print("python train_staged.py staged_training.yaml")
    
    return True


def show_configuration_examples():
    """
    æ˜¾ç¤ºé…ç½®ç¤ºä¾‹
    """
    print("\n" + "="*60)
    print("é…ç½®ç¤ºä¾‹")
    print("="*60)
    
    print("1. å¿«é€ŸéªŒè¯é…ç½® (quick_start.yaml):")
    print("   - åªè®­ç»ƒé˜¶æ®µ1ï¼ˆè¿æ¥å™¨ï¼‰")
    print("   - ä½¿ç”¨å•ä¸€æ•°æ®é›† (cocoqa)")
    print("   - å°æ‰¹é‡ï¼Œå¿«é€ŸéªŒè¯")
    
    print("\n2. å®Œæ•´è®­ç»ƒé…ç½® (staged_training.yaml):")
    print("   - è®­ç»ƒæ‰€æœ‰ä¸‰ä¸ªé˜¶æ®µ")
    print("   - ä½¿ç”¨å…¨é‡æ•°æ®")
    print("   - æ”¯æŒä¸‹æ¸¸ä»»åŠ¡")
    
    print("\n3. è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹:")
    print("   - ä¿®æ”¹å­¦ä¹ ç‡: stage1_lr: 0.0001")
    print("   - ä¿®æ”¹è®­ç»ƒè½®æ•°: stage1_epochs: 2")
    print("   - ä¿®æ”¹æ•°æ®é›†: train_data: 'all'")
    print("   - æ·»åŠ ä¸‹æ¸¸ä»»åŠ¡: downstream_tasks: ['captioning', 'vqa']")


def show_usage_examples():
    """
    æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹
    """
    print("\n" + "="*60)
    print("ä½¿ç”¨ç¤ºä¾‹")
    print("="*60)
    
    examples = [
        {
            "description": "å¿«é€ŸéªŒè¯ï¼ˆæ¨èæ–°æ‰‹ï¼‰",
            "command": "python train_staged.py quick_start.yaml",
            "explanation": "åªè®­ç»ƒè¿æ¥å™¨ï¼Œå¿«é€ŸéªŒè¯ç³»ç»Ÿæ˜¯å¦æ­£å¸¸å·¥ä½œ"
        },
        {
            "description": "å®Œæ•´è®­ç»ƒæµç¨‹",
            "command": "python train_staged.py staged_training.yaml", 
            "explanation": "è®­ç»ƒæ‰€æœ‰ä¸‰ä¸ªé˜¶æ®µï¼Œå®ç°æœ€ä½³æ€§èƒ½"
        },
        {
            "description": "åªè®­ç»ƒé˜¶æ®µ1",
            "command": "python train_staged.py --training_stage stage1 --train_data cocoqa",
            "explanation": "åªè®­ç»ƒè¿æ¥å™¨ï¼Œé€‚åˆèµ„æºå—é™ç¯å¢ƒ"
        },
        {
            "description": "åªè®­ç»ƒé˜¶æ®µ2",
            "command": "python train_staged.py --training_stage stage2 --train_data all",
            "explanation": "è®­ç»ƒè§†è§‰+è¿æ¥å™¨ï¼Œæå‡è§†è§‰ç†è§£èƒ½åŠ›"
        },
        {
            "description": "åªè®­ç»ƒé˜¶æ®µ3",
            "command": "python train_staged.py --training_stage stage3 --train_data all",
            "explanation": "å…¨é‡å¾®è°ƒï¼Œå®ç°æœ€ä½³æ€§èƒ½"
        },
        {
            "description": "ä»é˜¶æ®µ2æ¢å¤è®­ç»ƒ",
            "command": "python train_staged.py --resume_from_stage stage2 --training_stage all",
            "explanation": "ä»é˜¶æ®µ2å¼€å§‹ç»§ç»­è®­ç»ƒæ‰€æœ‰é˜¶æ®µ"
        }
    ]
    
    for i, example in enumerate(examples, 1):
        print(f"\n{i}. {example['description']}")
        print(f"   å‘½ä»¤: {example['command']}")
        print(f"   è¯´æ˜: {example['explanation']}")


def show_training_stages():
    """
    æ˜¾ç¤ºè®­ç»ƒé˜¶æ®µè¯´æ˜
    """
    print("\n" + "="*60)
    print("è®­ç»ƒé˜¶æ®µè¯´æ˜")
    print("="*60)
    
    stages = [
        {
            "name": "é˜¶æ®µ1: è¿æ¥å™¨è®­ç»ƒ",
            "frozen": ["è§†è§‰ç¼–ç å™¨", "æ–‡æœ¬æ¨¡å‹"],
            "trainable": ["è¿æ¥å™¨"],
            "purpose": "å­¦ä¹ è§†è§‰ç‰¹å¾åˆ°æ–‡æœ¬ç‰¹å¾çš„æ˜ å°„",
            "lr": "1e-4",
            "epochs": "1-2"
        },
        {
            "name": "é˜¶æ®µ2: è§†è§‰+è¿æ¥å™¨è®­ç»ƒ", 
            "frozen": ["æ–‡æœ¬æ¨¡å‹"],
            "trainable": ["è§†è§‰ç¼–ç å™¨", "è¿æ¥å™¨"],
            "purpose": "ä¼˜åŒ–è§†è§‰ç†è§£èƒ½åŠ›",
            "lr": "5e-5",
            "epochs": "1-3"
        },
        {
            "name": "é˜¶æ®µ3: å…¨é‡å¾®è°ƒ",
            "frozen": [],
            "trainable": ["æ‰€æœ‰å‚æ•°"],
            "purpose": "å®ç°æœ€ä½³æ€§èƒ½",
            "lr": "1e-5", 
            "epochs": "1-5"
        }
    ]
    
    for stage in stages:
        print(f"\n{stage['name']}")
        print(f"  å†»ç»“ç»„ä»¶: {', '.join(stage['frozen']) if stage['frozen'] else 'æ— '}")
        print(f"  å¯è®­ç»ƒç»„ä»¶: {', '.join(stage['trainable'])}")
        print(f"  ç›®çš„: {stage['purpose']}")
        print(f"  å»ºè®®å­¦ä¹ ç‡: {stage['lr']}")
        print(f"  å»ºè®®è®­ç»ƒè½®æ•°: {stage['epochs']}")


def show_troubleshooting():
    """
    æ˜¾ç¤ºæ•…éšœæ’é™¤æŒ‡å—
    """
    print("\n" + "="*60)
    print("æ•…éšœæ’é™¤æŒ‡å—")
    print("="*60)
    
    issues = [
        {
            "problem": "æ˜¾å­˜ä¸è¶³ (CUDA out of memory)",
            "solutions": [
                "å‡å°‘æ‰¹é‡å¤§å°: per_device_train_batch_size: 1",
                "å¢åŠ æ¢¯åº¦ç´¯ç§¯: gradient_accumulation_steps: 8", 
                "å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹: gradient_checkpointing: true",
                "ä½¿ç”¨æ›´å°çš„æ•°æ®é›†: train_data: 'cocoqa'"
            ]
        },
        {
            "problem": "è®­ç»ƒä¸ç¨³å®šï¼ˆæŸå¤±éœ‡è¡ï¼‰",
            "solutions": [
                "é™ä½å­¦ä¹ ç‡: stage1_lr: 5e-5",
                "å¢åŠ warmupæ¯”ä¾‹: warmup_ratio: 0.2",
                "ä½¿ç”¨æ›´ç¨³å®šçš„ä¼˜åŒ–å™¨: optim: 'adamw_torch'",
                "å¢åŠ æƒé‡è¡°å‡: weight_decay: 0.05"
            ]
        },
        {
            "problem": "æ”¶æ•›ç¼“æ…¢",
            "solutions": [
                "å¢åŠ è®­ç»ƒè½®æ•°: stage1_epochs: 3",
                "ä½¿ç”¨æ›´å¤šæ•°æ®: train_data: 'all'",
                "è°ƒæ•´å­¦ä¹ ç‡è°ƒåº¦: lr_scheduler_type: 'linear'",
                "æ£€æŸ¥æ•°æ®è´¨é‡"
            ]
        },
        {
            "problem": "æ¨¡å‹ä¿å­˜å¤±è´¥",
            "solutions": [
                "æ£€æŸ¥ç£ç›˜ç©ºé—´",
                "å‡å°‘ä¿å­˜é¢‘ç‡: save_steps: 50",
                "å‡å°‘ä¿å­˜æ•°é‡: save_total_limit: 3",
                "æ£€æŸ¥æ–‡ä»¶æƒé™"
            ]
        }
    ]
    
    for issue in issues:
        print(f"\nâŒ {issue['problem']}")
        for solution in issue['solutions']:
            print(f"   ğŸ’¡ {solution}")


def main():
    """
    ä¸»å‡½æ•°
    """
    print("æ¬¢è¿ä½¿ç”¨åˆ†é˜¶æ®µè®­ç»ƒç³»ç»Ÿï¼")
    
    # è¿è¡Œè®­ç»ƒç¤ºä¾‹
    success = run_training_example()
    
    # æ˜¾ç¤ºé…ç½®ç¤ºä¾‹
    show_configuration_examples()
    
    # æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹
    show_usage_examples()
    
    # æ˜¾ç¤ºè®­ç»ƒé˜¶æ®µè¯´æ˜
    show_training_stages()
    
    # æ˜¾ç¤ºæ•…éšœæ’é™¤æŒ‡å—
    show_troubleshooting()
    
    print("\n" + "="*60)
    print("æ€»ç»“")
    print("="*60)
    print("âœ… åˆ†é˜¶æ®µè®­ç»ƒç³»ç»Ÿå·²å‡†å¤‡å°±ç»ª")
    print("ğŸ“– è¯¦ç»†æ–‡æ¡£è¯·å‚è€ƒ: STAGED_TRAINING_README.md")
    print("ğŸš€ å¼€å§‹è®­ç»ƒ: python train_staged.py staged_training_test.yaml")
    print("="*60)


if __name__ == "__main__":
    main() 